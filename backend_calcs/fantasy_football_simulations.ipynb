{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d37e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2834589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9360c60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIMULATIONS = 10000\n",
    "SCORING_DICT = {\n",
    "    \"player_pass_tds\": 4,\n",
    "    \"player_pass_interceptions\": -2,\n",
    "    \"player_rush_or_rec_tds\": 6,\n",
    "    \"player_reception_yds\": 0.1,\n",
    "    \"player_rush_yds\": 0.1,\n",
    "    \"player_receptions\": 1,\n",
    "    \"player_pass_yds\": 0.04\n",
    "}\n",
    "\n",
    "REQUIRED_CATEGORIES_DICT = {\n",
    "    'QB':['player_pass_tds','player_pass_interceptions','player_pass_yds',],\n",
    "    'RB':['player_rush_or_rec_tds','player_rush_yds',],\n",
    "    'WR':['player_rush_or_rec_tds','player_reception_yds','player_receptions',],\n",
    "}\n",
    "\n",
    "PPR_TYPES = ['full','half','no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c488f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    connection = psycopg2.connect(\n",
    "    host=\"aws-0-us-west-1.pooler.supabase.com\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres.bazfvnkvwteendgaxumt\",\n",
    "    password='?ya21[Uta=T9!w]+e]4t',\n",
    "    port=6543\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "def import_data_supabase(supa_table):\n",
    "    try:\n",
    "        connection = create_connection()\n",
    "        df_prior = pd.read_sql(f'SELECT * FROM {supa_table} ORDER BY player,bet_category,point',connection)\n",
    "        \n",
    "\n",
    "        print(f'{len(df_prior)} rows pulled from {supa_table}')\n",
    "        return df_prior\n",
    "\n",
    "    except Exception as error:\n",
    "        raise RuntimeError(f\"Error while pulling prior data: {error}.\")\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c451a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mc_players(df_odds):\n",
    "    players_set = set(df_odds['player'])\n",
    "    mc_players = []\n",
    "    for player in players_set:\n",
    "        player_mask = df_odds['player'] == player\n",
    "        avail_categories = set(df_odds.loc[player_mask,'bet_category'])\n",
    "        for req_categories in REQUIRED_CATEGORIES_DICT.values():\n",
    "            if all(rc in avail_categories for rc in req_categories):\n",
    "                mc_players.append(player)\n",
    "                break\n",
    "    return mc_players\n",
    "\n",
    "def create_pct_dict(df_odds,mc_player):\n",
    "    pct_dict = {}\n",
    "    player_mask = df_odds['player'] == mc_player\n",
    "    for _,row in df_odds[player_mask].iterrows():\n",
    "        cat = row['bet_category']\n",
    "        pt = math.ceil(row['point'])\n",
    "        pct = row['pct_under']\n",
    "        \n",
    "        cur_cat = pct_dict.get(cat,[])\n",
    "        cur_cat.append((pt,pct))\n",
    "        pct_dict[cat] = cur_cat\n",
    "        \n",
    "    return pct_dict\n",
    "\n",
    "def calc_pts(cat,pct_dict):\n",
    "    if not (pts_list:=pct_dict.get(cat)):\n",
    "        return 0\n",
    "    for pts,pct in pts_list:\n",
    "        if random.random() >= pct:\n",
    "            return pts\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38d361d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_mc(mc_player,pct_dict):\n",
    "    cat_cols = [col for col in SCORING_DICT.keys()]\n",
    "    mc_cols = ['player'] + cat_cols\n",
    "    df_mc = pd.DataFrame(columns=mc_cols)\n",
    "    df_mc = df_mc.reindex(range(SIMULATIONS))\n",
    "    df_mc.loc[:,'player'] = mc_player\n",
    "    for col in cat_cols:\n",
    "        df_mc[col] = df_mc.apply(lambda x:calc_pts(col,pct_dict),axis=1)\n",
    "\n",
    "    # populate fantasy pts\n",
    "    for i,row in df_mc.iterrows():\n",
    "        total_score_ppr = 0\n",
    "        for cat in cat_cols:\n",
    "            pts = row[cat]\n",
    "            total_score_ppr += SCORING_DICT[cat] * pts\n",
    "\n",
    "        rec = row['player_receptions']\n",
    "        df_mc.at[i,'total_score_full_ppr'] = total_score_ppr\n",
    "        df_mc.at[i,'total_score_half_ppr'] = total_score_ppr - rec * 0.5\n",
    "        df_mc.at[i,'total_score_no_ppr'] = total_score_ppr - rec \n",
    "    return df_mc\n",
    "\n",
    "def create_chart_source(df_mc,ppr_type):       \n",
    "    max_score = 50\n",
    "    pts_dict =  {i: 0 for i in range(max_score + 1)}\n",
    "\n",
    "    for _,row in df_mc.iterrows():\n",
    "        total_score = int(round(row[f'total_score_{ppr_type}_ppr']))\n",
    "        pts_dict[total_score] += 1\n",
    "\n",
    "    for score in range(max_score + 1):\n",
    "        pts_dict[score] = round(pts_dict[score]/SIMULATIONS * 100,1)\n",
    "\n",
    "    chart_source = [{'pts':k,'pct':v} for k,v in pts_dict.items()]\n",
    "    return chart_source\n",
    "\n",
    "def create_single_row_dict(df_mc):\n",
    "    single_row_dict = {}\n",
    "    for col in df_mc.columns:\n",
    "        if col == 'player':\n",
    "            single_row_dict['player'] = df_mc[col][0]\n",
    "            continue\n",
    "\n",
    "        single_row_dict[col] = statistics.mean(df_mc[col])\n",
    "        \n",
    "    for ppr_type in PPR_TYPES:\n",
    "        single_row_dict[f'total_score_{ppr_type}_ppr_median'] = statistics.median(df_mc[f'total_score_{ppr_type}_ppr'])\n",
    "    \n",
    "    for ppr_type in PPR_TYPES:\n",
    "        single_row_dict[f'chart_source_{ppr_type}_ppr'] = create_chart_source(df_mc,ppr_type)\n",
    "        \n",
    "    return single_row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da5c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    connection = psycopg2.connect(\n",
    "    host=\"aws-0-us-west-1.pooler.supabase.com\",\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres.bazfvnkvwteendgaxumt\",\n",
    "    password='?ya21[Uta=T9!w]+e]4t',\n",
    "    port=6543\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "def export_data_supabase(df_export,supa_table):\n",
    "    df_export = df_export.replace({np.nan: None})  # supabase doesn't accept NaN\n",
    "    for col in df_export.columns:\n",
    "        sample_val = df_export[col][0]\n",
    "        if isinstance(sample_val,list):\n",
    "            df_export[col] = df_export.apply(lambda x:str(x[col]).replace(\"'\",'\"'),axis=1)\n",
    "    \n",
    "    values = [tuple(x) for x in df_export.to_numpy()]\n",
    "    insert_statement = f\"INSERT INTO {supa_table} ({', '.join(df_export.columns)}) VALUES %s\"\n",
    "\n",
    "    try:\n",
    "        connection = create_connection()\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(f'DELETE FROM {supa_table};')\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"{supa_table} deleted successfully.\")\n",
    "\n",
    "        psycopg2.extras.execute_values(cursor, insert_statement, values)\n",
    "        connection.commit()\n",
    "\n",
    "        print(f\"Data inserted {len(values)} rows into {supa_table} successfully.\")\n",
    "\n",
    "    except Exception as error:\n",
    "        print(f\"Error while inserting data: {error}. Commits rolled back.\")\n",
    "        connection.rollback()\n",
    "\n",
    "    finally:\n",
    "        # Close the cursor and connection\n",
    "        cursor.close()\n",
    "        connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "353bb812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "2024-10-02 19:05:53 - INFO - creating DataFrame...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2748 rows pulled from public.full_odds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 19:09:32 - INFO - DataFrame created, exporting to supabase...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public.chart_source deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-02 19:09:33 - INFO - all done.. hooray!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted 64 rows into public.chart_source successfully.\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "df_odds = import_data_supabase('public.full_odds')\n",
    "mc_players = create_mc_players(df_odds)\n",
    "\n",
    "data = []\n",
    "logging.info('creating DataFrame...')\n",
    "for mc_player in mc_players:\n",
    "    pct_dict = create_pct_dict(df_odds,mc_player)\n",
    "    df_mc = create_df_mc(mc_player,pct_dict)\n",
    "    single_row_dict = create_single_row_dict(df_mc)\n",
    "    data.append(single_row_dict)\n",
    "\n",
    "    df_full_results = pd.DataFrame(data)\n",
    "logging.info('DataFrame created, exporting to supabase...')\n",
    "export_data_supabase(df_full_results,'public.chart_source')\n",
    "logging.info('all done.. hooray!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39febd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# players list (id, name, team, position)\n",
    "players = [\n",
    "    {\"id\":\"patrick-mahomes\",\"name\":\"Patrick Mahomes\",\"team\":\"KC\",\"position\":\"QB\"},\n",
    "    {\"id\":\"christian-mccaffrey\",\"name\":\"Christian McCaffrey\",\"team\":\"SF\",\"position\":\"RB\"},\n",
    "    # ...generate this from your data\n",
    "]\n",
    "\n",
    "# projections keyed by the SAME id\n",
    "projections = [\n",
    "    {\"id\":\"patrick-mahomes\",\"ppr\":22.1,\"median\":21,\"ceiling\":35,\"floor\":12},\n",
    "    {\"id\":\"christian-mccaffrey\",\"ppr\":24.8,\"median\":23,\"ceiling\":40,\"floor\":10.5},\n",
    "    # ...your Monte Carlo outputs here\n",
    "]\n",
    "\n",
    "import json, os, pathlib\n",
    "out = pathlib.Path(\"../ff_react/public\")\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "(out/\"players.json\").write_text(json.dumps(players, indent=2))\n",
    "(out/\"projections.json\").write_text(json.dumps(projections, indent=2))\n",
    "print(\"Wrote to ff_react/public/players.json and projections.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
